---
title: On the Computational Benefit of Multimodal Learning
abstract: 'Human perception inherently operates in a multimodal manner. Similarly,
  as machines interpret the empirical world, their learning processes ought to be
  multimodal. The recent, remarkable successes in empirical multimodal learning underscore
  the significance of understanding this paradigm. Yet, a solid theoretical foundation
  for multimodal learning has eluded the field for some time. While a recent study
  by \cite{zhoul} has shown the superior sample complexity of multimodal learning
  compared to its unimodal counterpart, another basic question remains: does multimodal
  learning also offer computational advantages over unimodal learning? This work initiates
  a study on the computational benefit of multimodal learning. We demonstrate that,
  under certain conditions, multimodal learning can outpace unimodal learning exponentially
  in terms of computation. Specifically, we present a learning task that is NP-hard
  for unimodal learning but is solvable in polynomial time by a multimodal algorithm.
  Our construction is based on a novel modification to the intersection of two half-spaces
  problem.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lu24a
month: 0
tex_title: On the Computational Benefit of Multimodal Learning
firstpage: 810
lastpage: 821
page: 810-821
order: 810
cycles: false
bibtex_author: Lu, Zhou
author:
- given: Zhou
  family: Lu
date: 2024-03-15
address:
container-title: Proceedings of The 35th International Conference on Algorithmic Learning
  Theory
volume: '237'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 3
  - 15
pdf: https://proceedings.mlr.press/v237/lu24a/lu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
