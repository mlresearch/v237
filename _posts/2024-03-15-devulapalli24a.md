---
title: The Dimension of Self-Directed Learning
abstract: Understanding the self-directed learning complexity has been an important
  problem that has captured the attention of the online learning theory community
  since the early 1990s. Within this framework, the learner is allowed to adaptively
  choose its next data point in making predictions unlike the setting in adversarial
  online learning. In this paper, we study the self-directed learning complexity in
  both the binary and multi-class settings, and we develop a dimension, namely $SDdim$,
  that exactly characterizes the self-directed learning mistake-bound for any concept
  class. The intuition behind $SDdim$ can be understood as a two-player game called
  the â€œlabelling game". Armed with this two-player game, we calculate $SDdim$ on a
  whole host of examples with notable results on axis-aligned rectangles, VC dimension
  $1$ classes, and linear separators. We demonstrate several learnability gaps with
  a central focus between self-directed learning and offline sequence learning models
  that include either the best or worst ordering. Finally, we extend our analysis
  to the self-directed binary agnostic setting where we derive upper and lower bounds.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: devulapalli24a
month: 0
tex_title: The Dimension of Self-Directed Learning
firstpage: 544
lastpage: 573
page: 544-573
order: 544
cycles: false
bibtex_author: Devulapalli, Pramith and Hanneke, Steve
author:
- given: Pramith
  family: Devulapalli
- given: Steve
  family: Hanneke
date: 2024-03-15
address:
container-title: Proceedings of The 35th International Conference on Algorithmic Learning
  Theory
volume: '237'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 3
  - 15
pdf: https://proceedings.mlr.press/v237/devulapalli24a/devulapalli24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
