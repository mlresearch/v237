---
title: Computation with Sequences of Assemblies in a Model of the Brain
abstract: 'Even as machine learning exceeds human-level performance on many applications,
  the generality, robustness, and rapidity of the brain’s learning capabilities remain
  unmatched. How cognition arises from neural activity is <em> the</em> central open
  question in neuroscience, inextricable from the study of intelligence itself. A
  simple formal model of neural activity was proposed in Papadimitriou (2020) and
  has been subsequently shown, through both mathematical proofs and simulations, to
  be capable of implementing certain simple cognitive operations via the creation
  and manipulation of assemblies of neurons. However, many intelligent behaviors rely
  on the ability to recognize, store, and manipulate temporal <em> sequences </em>
  of stimuli (planning, language, navigation, to list a few). Here we show that, in
  the same model, time can be captured naturally as precedence through synaptic weights
  and plasticity, and, as a result, a range of computations on <em> sequences </em>
  of assemblies can be carried out.  In particular, repeated presentation of a sequence
  of stimuli leads to the memorization of the sequence through corresponding neural
  assemblies: upon future presentation of any stimulus in the sequence, the corresponding
  assembly and its subsequent ones will be activated, one after the other, until the
  end of the sequence.  If the stimulus sequence is presented to two brain areas simultaneously,
  a scaffolded representation is created, resulting in more efficient memorization
  and recall, in agreement with cognitive experiments. Finally, we show that any finite
  state machine can be learned in a similar way, through the presentation of appropriate
  patterns of sequences.  Through an extension of this mechanism, the model can be
  shown to be capable of universal computation. We support our analysis with a number
  of experiments to probe the limits of learning in this model in key ways. Taken
  together, these results provide a concrete hypothesis for the basis of the brain’s
  remarkable abilities to compute and learn, with sequences playing a vital role.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dabagia24a
month: 0
tex_title: Computation with Sequences of Assemblies in a Model of the Brain
firstpage: 499
lastpage: 504
page: 499-504
order: 499
cycles: false
bibtex_author: Dabagia, Max and Papadimitriou, Christos and Vempala, Santosh
author:
- given: Max
  family: Dabagia
- given: Christos
  family: Papadimitriou
- given: Santosh
  family: Vempala
date: 2024-03-15
address:
container-title: Proceedings of The 35th International Conference on Algorithmic Learning
  Theory
volume: '237'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 3
  - 15
pdf: https://proceedings.mlr.press/v237/dabagia24a/dabagia24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
